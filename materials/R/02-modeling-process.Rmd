---
title: "Module 02: Modeling Process"
output: html_notebook
---

# Prerequisites

This module leverages the following packages.

```{r}
# Helper packages
library(tidyverse)

# Modeling process
library(tidymodels)
```


Data required
```{r}
# Ames housing data
ames = read_csv("../data/ames.csv")

# Job attrition data
attrition = read_csv("../data/attrition.csv")
```


# Data splitting

## Simple random sampling

```{r}
# create train/test split
set.seed(123)  # for reproducibility
split  <- initial_split(ames, prop = 0.7)
train  <- training(split)
test   <- testing(split)

# dimensions of training data
dim(train)
```

```{r}
ggplot(train, aes(Sale_Price)) +
 geom_density(color = "blue") +
 geom_density(data = test, color = "red") +
 ggtitle("Random sampling with R")
```


## Stratified sampling

```{r}
set.seed(123)
split_strat <- initial_split(attrition, prop = 0.7, strata = "Attrition")
train_strat <- training(split_strat)
test_strat  <- testing(split_strat)
```

```{r}
# orginal response distribution
table(attrition$Attrition) %>% prop.table()

# response distribution for training data
table(train_strat$Attrition) %>% prop.table()

# response distribution for test data
table(test_strat$Attrition) %>% prop.table()
```


# Creating models

```{r}
knn <- nearest_neighbor(neighbors = 10) %>%
  set_engine("kknn") %>%
  set_mode("regression")

m1 <- fit(knn, formula = Sale_Price ~ Gr_Liv_Area + Year_Built, data = train)

m1
```

```{r}
m1 %>% predict(new_data = train)
```


# Evaluating models

## Regression model

```{r}
m1
```

```{r}
pred <- m1 %>%  predict(new_data = train)

rmse_vec(truth = train$Sale_Price, estimate = pred$.pred)
```

## Classification model

```{r}
# convert response variable to a factor
train_strat$Attrition <- as.factor(train_strat$Attrition)

# fit model to attrition data
m2 <- nearest_neighbor(neighbors = 10) %>%
  set_engine("kknn") %>%
  set_mode("classification") %>%
  fit(Attrition ~ DistanceFromHome, data = train_strat)

# make predictions
pred <- m2 %>%  predict(new_data = train_strat, type = "prob")

# compute AUC
roc_auc_vec(truth = train_strat$Attrition, estimate = pred$.pred_Yes, event_level = "second")
```


# Resampling

```{r}
# create 10 fold CV object
kfold <- vfold_cv(train, v = 10)
results <- fit_resamples(knn, Sale_Price ~ Gr_Liv_Area + Year_Built, kfold)

# see RMSE for all folds
collect_metrics(results, summarize = FALSE) %>% filter(.metric == "rmse")

# average RMSE
collect_metrics(results, summarize = TRUE)
```

```{r}
# 10 fold cross validation repated 5 times (total of 50 folds)
rfk <- vfold_cv(train, v = 10, repeats = 5)
results <- fit_resamples(knn, Sale_Price ~ Gr_Liv_Area + Year_Built, rfk)

# see RMSE for all folds
collect_metrics(results, summarize = FALSE) %>% filter(.metric == "rmse")

# average RMSE
collect_metrics(results, summarize = TRUE)
```


# Hyperparameter tuning

```{r}
# model object
knn <- nearest_neighbor(neighbors = tune()) %>%
  set_engine("kknn") %>%
  set_mode("regression")

# Create grid of hyperparameter values
hyper_grid <- expand.grid(neighbors = seq(2, 25, by = 1))

# model recipe
model_form <- recipe(Sale_Price ~ Gr_Liv_Area + Year_Built, data = train)

# Tune a knn model using grid search
results <- tune_grid(knn, model_form, resamples = kfold, grid = hyper_grid)

show_best(results, metric = "rmse")
```

```{r}
results %>%
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  ggplot(aes(neighbors, mean)) +
  geom_line() +
  geom_point() +
  labs(x = "k", y = "RMSE", title = "Cross validated grid search results")
```

# Putting the process together

```{r}
# create train/test split
set.seed(123)  # for reproducibility
split  <- initial_split(ames, prop = 0.7)
train  <- training(split)
test   <- testing(split)

# select only numeric features
train <- train %>% select_if(is.numeric)

# model object
knn <- nearest_neighbor(neighbors = tune()) %>%
  set_engine("kknn") %>%
  set_mode("regression")

# Create grid of hyperparameter values
hyper_grid <- expand.grid(neighbors = seq(2, 25, by = 1))

# model recipe - Sale price is a function of all numeric features
model_form <- recipe(Sale_Price ~ ., data = train)

# Tune a knn model using grid search
results <- tune_grid(knn, model_form, resamples = kfold, grid = hyper_grid)

# best model
show_best(results, metric = "rmse")

# plot results
results %>%
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  ggplot(aes(neighbors, mean)) +
  geom_line() +
  geom_point() +
  labs(x = "k", y = "RMSE", title = "Cross validated grid search results")
```

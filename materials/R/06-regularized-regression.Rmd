---
title: "Regularized Regression"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Prerequisites


```{r}
# Helper packages
library(recipes)   # for feature engineering
library(tidyverse) # general data munging

# Modeling packages
library(glmnet)   # for implementing regularized regression
library(caret)    # for automating the tuning process
library(rsample)  # for sampling

# Model interpretability packages
library(vip)      # for variable importance
```


```{r prereqs-data}
# ames data
ames <- AmesHousing::make_ames()
# split data
set.seed(123)
split <- initial_split(ames, strata = "Sale_Price")
ames_train <- training(split)
```


# Data prep

* glmnet only accepts the non-formula XY interface so prior to modeling we need to separate our feature and target sets and

* dummy encode our feature set 

```{r}
# Create training  feature matrices
# we use model.matrix(...)[, -1] to discard the intercept
X <- model.matrix(Sale_Price ~ ., ames_train)[, -1]

# transform y with log transformation
Y <- log(ames_train$Sale_Price)
```


# glmnet

Pro Tip: glmnet can auto-generate the appropriate λ values based on the data; the vast majority of the time you will have little need to adjust this default.

Ridge:

```{r}
ridge <- glmnet(
  x = X,
  y = Y,
  alpha = 0
)

plot(ridge, xvar = "lambda")
```

Lasso:

```{r}
lasso <- glmnet(
  x = X,
  y = Y,
  alpha = 1
)

plot(lasso, xvar = "lambda")
```

So which one is better? We can use `cv.glmnet` to provide cross-validated results

Ridge CV model:

```{r}
ridge <- cv.glmnet(
  x = X,
  y = Y,
  alpha = 0
)

plot(ridge)
```

Lasso CV model:

```{r}
lasso <- cv.glmnet(
  x = X,
  y = Y,
  alpha = 1
)

plot(lasso)
```


Ridge model results: 

```{r}
# Ridge model - minimum MSE
min(ridge$cvm)

# Ridge model - lambda for this min MSE
ridge$lambda.min 

# Ridge model w/1-SE rule
ridge$cvm[ridge$lambda == ridge$lambda.1se]

# Ridge model w/1-SE rule -- No. of coef | 1-SE MSE
ridge$nzero[ridge$lambda == ridge$lambda.1se]
```

Lasso model results: 

```{r}
# Lasso model - minimum MSE
min(lasso$cvm)       

# Lasso model - lambda for this min MSE
lasso$lambda.min 

# Lasso model - w/1-SE rule
lasso$cvm[lasso$lambda == lasso$lambda.1se]

# Lasso model w/1-SE rule -- No. of coef | 1-SE MSE
lasso$nzero[lasso$lambda == lasso$lambda.1se]
```


# Grid search

Often, the optimal model contains an alpha somewhere between 0–1, thus we want to tune both the λ and the alpha parameters. 

```{r cv-glmnet}
# tuning grid
hyper_grid <- expand.grid(
  alpha = seq(0, 1, by = .25),
  lambda = c(0.1, 10, 100, 1000, 10000)
)

# perform resampling
set.seed(123)
cv_glmnet <- train(
  x = X,
  y = Y,
  method = "glmnet",
  preProc = c("zv", "center", "scale"),
  trControl = trainControl(method = "cv", number = 10),
  tuneLength = 10
)

# best model
cv_glmnet$results %>%
  filter(
    alpha == cv_glmnet$bestTune$alpha,
    lambda == cv_glmnet$bestTune$lambda
  )
```

```{r cv-glmnet-plot, fig.height=5}
# plot results
plot(cv_glmnet)
```

# Comparing results to previous models

* So how does this compare to our previous best model for the Ames data set? 
* Keep in mind that for this module we log transformed the response variable (`Sale_Price`). 
* Consequently, to provide a fair comparison to our previously model(s) we need to re-transform our predicted values.

```{r}
# predict sales price on training data
pred <- predict(cv_glmnet, X)

# compute RMSE of transformed predicted
RMSE(exp(pred), exp(Y))
```


# Feature importance

```{r}
vip(cv_glmnet, num_features = 20, geom = "point")
```

# Partial dependence plots

```{r regularized-top4-pdp, echo=FALSE, fig.height=8, fig.width=12}
p1 <- pdp::partial(cv_glmnet, pred.var = "Gr_Liv_Area", grid.resolution = 20) %>%
  as_tibble() %>% 
  mutate(yhat = exp(yhat)) %>%
  ggplot(aes(Gr_Liv_Area, yhat)) +
  geom_line() +
  scale_y_continuous(limits = c(0, 300000), labels = scales::dollar)

p2 <- pdp::partial(cv_glmnet, pred.var = "Total_Bsmt_SF", grid.resolution = 20) %>%
  as_tibble() %>% 
  mutate(yhat = exp(yhat)) %>%
  ggplot(aes(Total_Bsmt_SF, yhat)) +
  geom_line() +
  scale_y_continuous(limits = c(0, 300000), labels = scales::dollar)

p3 <- pdp::partial(cv_glmnet, pred.var = "Overall_QualExcellent") %>%
  as_tibble() %>% 
  mutate(
    yhat = exp(yhat),
    Overall_QualExcellent = factor(Overall_QualExcellent)
  ) %>%
  ggplot(aes(Overall_QualExcellent, yhat)) +
  geom_boxplot() +
  scale_y_continuous(limits = c(0, 300000), labels = scales::dollar)

p4 <- pdp::partial(cv_glmnet, pred.var = "Year_Built", grid.resolution = 20) %>%
  as_tibble() %>% 
  mutate(yhat = exp(yhat)) %>%
  ggplot(aes(Year_Built, yhat)) +
  geom_line() +
  scale_y_continuous(limits = c(0, 300000), labels = scales::dollar)

grid.arrange(p1, p2, p3, p4, nrow = 2)
```
